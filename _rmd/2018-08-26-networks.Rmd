---
title: "The century of complexity"
author: matt_gregory
comments: yes
date: '2018-08-26'
modified: `r format(Sys.time(), '%Y-%m-%d')`
layout: post
excerpt: "How network science can help"
published: FALSE
status: process
tags:
 - Networks
 - Network
 - Graph
 - Algorithm
categories: Rstats
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  dev = "svg",
  include = TRUE,
  message = FALSE,
  warning = FALSE,
  error = FALSE,
  cache = TRUE
  )
```

The universe is hopelessly complicated. Within it are systems that make the mind boggle. Think of the number of interconnected neurons in your brain required to understand this sentence ( [connectome](http://www.humanconnectomeproject.org/)); and the [network of interactions](https://en.wikipedia.org/wiki/Gene_regulatory_network) between genes, proteins and metabolites required to make the [cellular network](https://www.humancellatlas.org/) that is prereqisite to life (Barbasi, 2018).  

> “I think the next century will be the century of complexity.” - Stephen Hawking  

All is not lost. These seemingly intractably complicated problems can and have been succesffully modelled. This is particulalry apparent in some of the most succesful companies that have leveraged network science for profit. This also emphasises the empirical and data driven nature of network science.   

In addition to the conspicuous applied succeses of network science (e.g. see [Facebook's value](https://www.forbes.com/companies/facebook/)). A key discovery of network science is that the architecture of networks emerging in various domains of science, nature, and technology are similar to each other, a consequence of being governed by the same organizing principles. Consequently we can use a common set of mathematical tools to explore these systems.  

We use R as it has a bunch of [awesome packages for network analysis](https://github.com/qinwf/awesome-R#network-analysis). We also consider how you might deploy a visualisation of your network locally and online.  

The objectives of this post are to:  

* use a simple example to teach you the fundamental units and language of network science.  
* provide links to other resources for more code examples.  
* use R to understand a real world business example network and answer typical questions.  
* consider converting into a graph data base using Docker and Neo4j.  
* provide some interactive visualisation options that scale with or without dev support.    

## Your first network

Fundamentally a network is stuff connected to other stuff through a relationship. It's very generaliseable and can be applied to an incredible breadth of problems.  

This is probably not your first run-in with network science. Did you ever draw a food web at school? Let's use R to recreate and relive that joy of sketching a simple food web. We'll use this to understand the language fundamentals of networks that will scaffold our understanding to visualising and analysing a more complicated real world business data set. This will allow you to spot the opportunity for using graphs and network science to solve a range of problems in your organisation.    

## Graph fundamentals

Soil science isn't widely regarded as being sexy but my [co-blogger](https://dspace.lib.cranfield.ac.uk/handle/1826/9298) might disagree with this assertion. To help promote this important discipline we use it as our basis for a [soil food web](https://en.wikipedia.org/wiki/Soil_food_web) and a model complex system (which we greatly simplify).    

A food web is an extension of the concept of a food chain which allows for a more detailed description of how species depend on each other. A food web can be modelled via a graph in which the nodes (or vertices) represent the species and the edges (links or relationships) represent feeding connections (energy flow); an edge from node A to node B indicates species B consumes species A. Note how there is a direction to the edge; FROM one node TO another, thus we say it is a "directed" graph. We use the `igraph::graph_from_literal` function as it is useful if you want to create a small (named) graph quickly, it works for both directed and undirected graphs.  

From `?` we read that we must supply one or more R expressions giving the structure of the graph. The expressions consist of vertex names and edge operators. An edge operator is a sequence of ‘-’ and ‘+’ characters, the former is for the edges and the latter is used for arrow heads. The edges can be arbitrarily long, i.e. you may use as many ‘-’ characters to “draw” them as you like (this [tutorial](http://kateto.net/ruworkshop#21_create_networks) provides greater depth and exploration of `igraph` network creation functions).

```{r}
library(igraph)

# build the graph
# the -+ can be thought of as a directed arrow, from left to right
soil_web <- graph_from_literal(A -+ B)
soil_web
```

The first line always starts with IGRAPH, showing you that the object is an `igraph graph`. For interpreting the rest of the output see the [relevant help](http://igraph.org/r/doc/print.igraph.html) of the `igraph` manual. What does the "D" mean?    

We also have easy access to nodes, edges with:

```{r}
E(soil_web)       # The edges of the "soil_web" object

V(soil_web)       # The vertices of the "soil_web" object

```

## Simple visualisation

More generally, if we want to understand a complex system, we need to know how its components interact with each other in a more human-readable format. In other words we need a map of its wiring diagram.   

```{r 2018-08-26-soil_web, fig.height=3, fig.width=3}
# make visualisation reproducible
set.seed(255)
# visualise it
plot(soil_web)
```

There are [many approaches](http://kateto.net/ruworkshop#4_plotting_network_data) you can use to prettify and customise your visualisation within R. You can even create interactive plots for this. In this blog post we focus on alternative software that has the graph database Neo4J as its core, but first we think about how we represent this data. How do we go about capturing this data in the first place?    

## Representing graphs

Representing data as a graph is very generaliseable and may be better suited to a problem than traditional relational databases, depending on the type of questions your users are interested in asking.  

Let's increase the complexity of our soil food web by adding an extra species and including scavenging relationships as well as predation.  

```{r 2018-08-26-soil_web2, fig.height=3, fig.width=3}
# build the more complicated directed graph or digraph
soil_web2 <- graph_from_literal(A -+ B, B -+ C,
                                C -+ B, C -+ A)

# visualise it
# A eats B, B scavenges on C, C scavenges on B, C eats A
plot(soil_web2)
```

We now consider how we might represent this data mathematically.  

### Adjacency matrix

A very common way to define graphs is via a two dimensional array known as an adjacency [matrix](http://networksciencebook.com/chapter/2#matrix). Continuing from the example above, how would we represent this graph as a matrix?  

We'll break this down into simple steps, first we create an empty [square matrix](https://en.wikipedia.org/wiki/Square_matrix) correpsonding to the number of species in our food web (or nodes in our graph).  

```{r}
# create an empty matrix to hold our relationships
m <- matrix(data = 0,
            nrow = 3, ncol = 3,
            dimnames = list(
              # row names, i
              c("A", "B", "C"),
              # col names, j
              c("A", "B", "C")
              )
            )

m
```

Thus we have three species all unconnected. Let's add our connections from our "complicated" food web. As we have named our dimensions, we can use these to assign a value to the relationship, or we can use regular matrix indexing by supplying a 1d index for each dimension, separated by a comma.  

```{r}
# from A to B, or A eats B
m["A", "B"] <- 1
m
```
Species B scavenges on species C:

```{r}
# from B to C
m[2, 3] <- 1
m
```

And the last two relationships where C eats A and C scavenges B (here we mix methods as experimentation helps us learn, try it out yourself):  

```{r}
# from C to A and from C to B
m[c("C", "C"), c(1, 2)] <- 1
m
```

When reading these matrices remember that the rows tell you FROM and the columns TO. So FROM A to B should draw an arrow in your mind from node A to B, thus A eats B.  

This format is machine readable but not particularly human readable. For most graphs it will also be a sparse matrix, with mostly zeroes, as most nodes will be unconnected. Sparseness has important consequences on the way we explore and store real networks. For example, when we store a large network in our computer, it is better to store only the list of links to avoid blocking out too much memory.  

We introduce the adjacency matrix here as it's quite straight forward and many network packages in R use the adjacency matrix to create specific classes for the appropriate packages (see this [blog by Jesse Saddler](https://www.jessesadler.com/post/network-analysis-with-r/) for some examples).

As well as memory issues, we note another weakness of this approach, our edges are not labelled. We fail to distinguish between whether the relationship is predation or scavenging. Thus we could improve things by using a graph database that stores these additional characteristics of the relationship.  

Another problem is that humans who capture this data in the first instance (typically in a spreadsheet) are unlikely to have the data in this format. We discuss different representational formats later.  

### Useful statistics

There's a bunch of useful characteristics of our graph that we can calculate using standard approaches described [here](http://networksciencebook.com/chapter/2#degree). These help us ask questions about the [connectedness of a graph](http://networksciencebook.com/chapter/2#connectedness), [distances between nodes](http://networksciencebook.com/chapter/2#paths) and the the degree to which the neighbors of a given node link to each other ( [clustering](http://networksciencebook.com/chapter/2#clustering)).  

```{r}
# the number of a nodes adjacent edges
# how many links does it have?
# this could help us identify keystone species
degree(soil_web2)
```

Given the above toy example we'll use a real world data set later in this post to explore graph statistics and useful algorithms for solving problems.  

## Spreadsheet friendly representation?

Most organisations are stuck collecting and manipulating data in spreadsheets. Can we represent our network in one spreadsheet?  

Those of you familiar with the `tidyverse` and the concept of the [tidy data set](http://vita.had.co.nz/papers/tidy-data.html) will . Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table.

We could just use one spreadsheet to capture the above information that is also arguably a bit easier for a human to interpret (and enter data for). All we need is information of which edge goes where (importantly each node must have a unique identifier). We call this information an edge list, where we need to know what node an edge goes FROM and TO. We'll draw an edge list for our example above.  

```{r}
library(tidyverse)
# Where Species A is id 1, Species B id 2, Species C id 3
# We could have a dictionary to translate the id to species name
edge_list <- tibble(from = c(1, 2, 3, 3), to = c(2, 3, 1, 2))

edge_list

```

A quick sense check; does this have the same number of edges as our adjacency matrix?  

```{r}
if (nrow(edge_list) == sum(m)) {
  print("The number of rows in the edge list equals the sum of ones in the adjacency matrix!")
}
```

### Edge attributes

Is this sufficient? What might we be missing? Earlier we mentioned how our relationships or edges were directed. We get this information by the FROM and TO but we can enhance it by providing a description of the type of relationship.  

```{r}
# Where Species A is id 1, Species B id 2, Species C id 3
edge_list <- edge_list %>%
  # describe the type of interaction
  # we use CAPS as it's the convention for Neo4j, a popular graph database
  mutate(description = c("PREDATES", "SCAVENGES", "SCAVENGES", "PREDATES"))

edge_list
```

### Edge weights

We can also add a weight to the edge which could be informative. In this example we can pretend that we have captured quantitative data for the relative biomass provided by each food source. For example, if Species A gets all its food from Species B and Species C gets most of its food from eating Species B but some of it from scavenging on Species A. We can incorporate this information that could be used later, perhaps to adjust the thickness of our edges between nodes (showing the strength of dependence of one species on another).  

```{r}
edge_list <- edge_list %>%
  mutate(prop_of_diet = c(1, 1, 0.2, 0.8))

edge_list
```

### Node attributes

If we included a seperate node list we could have an attributes column that helps us describe the characteristics of each species, that could be useful or provide further insight for our interpretation. For example, most products are now being classified as gluten-free or not, thus we might like to add this extra information into our food web so that our discerning species can decide on an appropriate food source to meet their dietary needs.  

This can be very handy for spotting patterns and later analysis, so ensure you use an informative description that will meet your analytical needs later.  

```{r}
# provide unique ids for each node
# add some additional columns / description of our nodes
# this could be many atrributes that we could filter on later
node_list <- tibble(id = 1:3, description = c("gluten", "gluten-free", "gluten"))

node_list
```

Alongside our unique id for each node and edge we could also include a human readable id, or instead use a unique character string or name as the id.  

For a guide on how to convert a typical dataset into an edge and node list see [Jesse Saddler's blog](https://www.jessesadler.com/post/network-analysis-with-r/).  

### Translating from unique id to name

Above we used a unique id for each species but we might want to readily convert back to our human readable name using a dictionary or by storing the name in our edge list (we could also use the ). Accessing the dictionary using hashes (i.e. using a specialised package) can outperform native named lists and vectors but if performance is an issue you should probably be storing your graph database in a dedicated graphDB like [Neo4j](https://neo4j.com/).  

For our example above we can make use of the `LETTERS` object.  

```{r}
# in Neo4j CamelCase is preferred for nodes
node_list <- node_list %>%
  mutate(
    species_name = LETTERS[id]
         )
# we can use species_name if we want to visualise
node_list
# same could be used for edge_list
```

## Tidygraph

Both node and edge data by itself fits very well within the tidy concept as each node and edge is, in a sense, a single observation. Thus, a close approximation of tidyness for relational data is two tidy data frames, one describing the node data and one describing the edge data. [tidygraph](https://www.data-imaginist.com/2017/introducing-tidygraph/) sits on top of the well-oiled machinery provided by the aforementioned `igraph`. `tidygraph` subclasses `igraph` with the `tbl_graph` class and simply exposes it in a tidy manner.  

```{r}
library(tidygraph)

# our food web is a directed graph
food_web <- tbl_graph(nodes = node_list, edges = edge_list, 
          directed = TRUE)

# tbl_graph inherits from igraph
class(food_web)

# we store the data as two tidy dataframes
food_web
```

In this format we can now plot using the `ggplot2`-like package `ggraph` (pronounced g-giraffe or g-g-raff). See the [manual](https://cran.r-project.org/web/packages/ggraph/ggraph.pdf) for details or this [blog post](https://www.jessesadler.com/post/network-analysis-with-r/).  

```{r 2018-08-26-soil_web2}
library(ggraph)

ggraph(food_web, layout = "linear") + 
  geom_edge_arc(aes(width = prop_of_diet),
                arrow = arrow(length = unit(1.5, "mm")), 
                start_cap = circle(3, "mm"),
                end_cap = circle(3, "mm"),
                alpha = 0.5) + 
  scale_edge_width(range = c(0.2, 2)) +
  geom_node_text(aes(label = species_name),
                 size = 5, color = "red",
                 position = "identity") +
  labs(edge_width = "Proportion of diet") +
  theme_graph()

```

As you can see there's a whole bunch of options and customisation depth that can be explored using the help or manual for `ggraph`.  

```{r 2018-08-26-soil_web2b}

food_web %>%
  ggraph(layout = "nicely") +
    geom_edge_link(
      aes(colour = description),
      arrow = arrow(length = unit(1.5, "mm")),
      start_cap = circle(3, "mm"),
      end_cap = circle(3, "mm")
    ) +
    geom_node_text(aes(label = species_name), size = 5) +
    scale_edge_colour_manual(values = c(PREDATES = "#22B022",
                                        SCAVENGES = "#A4AAF6")) +
    theme_graph() +
    labs(
      title = 'A soil food web',
      subtitle = "Nodes represent species, edges - energy flow",
      caption = "@mammykins_"
    )

```

This example provided the basics but lets scale things up a bit to data sets encountered by smaller organisations where its still comfortable to store the data using conventional means rather than using a graph database (often [real world networks](http://networksciencebook.com/chapter/2/#table-2-1) can get quite big!).  

## A real example - Government Innovation and Emerging Technology useage

With the popularisation of terms such as "social network" over the last decade, organisations are becoming more adept at spotting networks and the opportunity for using network science to provide business insight.  

The UK Government recently published a good example. In 2017, the Director General of the Government Digital Service (GDS) commissioned a [landscape review of technology innovation across government](https://www.gov.uk/government/publications/technology-innovation-in-government-survey/technology-innovation-in-government-survey) from an independent contractor (a non-random or convenience survey: likely to have sampling bias). The accrued information was transliterated into a machine readable format by the Innovation Team of the [Government Digital Service](https://www.gov.uk/government/publications/government-innovation-and-emerging-technology-underlying-data-set). The data shows the state of cross-government emerging technology use. We explore this data in R to act as a case study for other organisations.  

The data is provided as an [edge list](https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/734840/Government_Innovation_and_Emerging_Technology_network_graph-edges__1__-_Government_Innovation_and_Emerging_Technology_network_graph-edges__1_.csv/preview) and [node list](https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/734841/Government_Innovation_and_Emerging_Technology_network_graph-nodes__1_.csv/preview) as described earlier. This makes it straight forward to explore in R.  

## The data

We read the data into R and create a `tbl_graph` object. We inspect the data online beforehand and notice a lot of missing data for some column types. All the `Weights` appear to be set to 1 so are meaningless. This is likely the data output from the Graph Commons export as csv (we discuss later). You can see this for yourself when we print our `tbl_graph` named `inno`.     

```{r}

edge_list <- readr::read_csv("https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/734840/Government_Innovation_and_Emerging_Technology_network_graph-edges__1__-_Government_Innovation_and_Emerging_Technology_network_graph-edges__1_.csv", col_names = TRUE)


  
node_list <- readr::read_csv("https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/734841/Government_Innovation_and_Emerging_Technology_network_graph-nodes__1_.csv", col_names = TRUE)

inno <- tbl_graph(nodes = node_list, edges = edge_list, 
                  directed = TRUE)

inno
```

Printing out the two tidy tibbles of our nodes and edges is similar to looking at one tibble. However, from our musings earlier we discussed how it doesn't make sense to represent our graph as one tidy dataframe thus we have to "activate" our focus onto either the `Node Data` or the `Edge Data`. This is shown above by the `(active)` next to the `Node Data`.  

The notion of an active tibble within a `tbl_graph` object makes it possible to manipulate the data in one tibble at a time. The nodes tibble is activated by default, but you can change which tibble is active with the `activate()` function (two new pipes have been added that performs the activate step implicitly: `%N>%` will activate nodes and `%E>%` will activate edges). Thus, if we wanted to filter the rows in the edges tibble to list those projects that use deep learning, we could use `activate()` and then `filter()`. Here we simply print out the result rather than assigning it (we use the implicit `%E>%` pipe with activate operator).  

```{r}
# What happens if you remove the E? (you don't activate edges?)
inno %E>%
  filter(`To Name` == "Deep Learning") %>%
  tidygraph::as_tibble() %>%
  nrow()
```

The [newer versions](https://www.data-imaginist.com/2018/tidygraph-1-1-a-tidy-hope/) of `tidygraph` also introduces `morph()` allowing you to make tempoary topology changes to your network.  

This takes some getting use to, to create the query you want.  We suggest consulting the [manual](https://rdrr.io/cran/tidygraph/man/) for more options. We give a few other examples below.  

We can also do network-sciency things as well as the standard `dplyr` fare. Perhaps we want to drop "isolated" nodes, nodes that don't connect with the rest of the network (see `?node_is` for a bunch of useful logical checks that lets the user query whether each node is of a certain type).   

```{r}
inno %>%
  # Remove isolated nodes
  activate(nodes) %>%
  # drop isolated nodes
  filter(!node_is_isolated()) %>%
  tidygraph::as_tibble() %>%
  nrow()
  
```

### inno schema

The nodes are of different types. Here we've loaded the data into Neo4j and got the schema or map of relationships that this network captures (we discuss this in a later section).  

This is trivial when using Docker. We can create a [Neo4j instance using Docker](https://hub.docker.com/_/neo4j/) that runs locally on our browser into which we can load our data.  

![](./figures/2018-08-26-gov_schema.png)

`PublicOrganisation`s like "Government Digital Service" CONTRIBUTE to `Projects`, sometimes collaborating with other `PublicOrganisations` or `PrivateOrganisations`. These projects USE a named `Technology` which is considered by the authors to be an emerging or innovative technology.  

## What can network analysis tell us?

While visualisations are useful, sometimes they can be overused, as evident when shown a hairball. What we need is a series of logical operation or functions that can be piped together as with `dplyr`.  

To answer our questions we need to remember that the main data structure of tidygraph is a `tbl_graph` which can be thought of as two tibbles with data for nodes and edges. Inspecting the `Edge Data` tibble values in the `from` and `to` we can see the row indices of the nodes stored in the `Node Data` tibble (we can use `as_tibble` to access the active tibble).  

Typically network analysis can be used to explore relationships in social or professional networks like this. We might be interested in asking questions like:

### Can we place a value on this network?

[Metcalfe’s law](https://en.wikipedia.org/wiki/Metcalfe%27s_law) states that the value of a network is proportional to the square of the number of its nodes, i.e. N^2^. Formulated around 1980 in the context of communication devices, it implies that as you gain more users the value of your network increases. Indeed, the more of your friends use [WhatsApp](https://www.whatsapp.com/), the more valuable the service is to you.  

```{r}
# what's the value of our network?
# what are our nodes of interest?
# what might we consider our users?
inno %>%
  # Remove isolated nodes
  activate(nodes) %>%
  # drop isolated nodes
  filter(Type %in% "PublicOrganisation") %>%
  tidygraph::as_tibble() %>%
  nrow() %>%
  # here i do something weird
  # Every operation is a function call
  # Note that `, the backtick,
  # lets you refer to functions or variables
  # that have otherwise reserved or illegal names
  # I raise N to the power of 2, or square it
  `^`(2)


```

Wow that's a big number!? Or is it...  

Two problems with this might spring to mind. Most real networks are sparse; only a small proportion of the total possible edges exist between nodes (the network is very far from being fully connected). Second, not all relationships or edges in your network are of equal value. Some edges are used heavily while most are rarely used. In essence a real network tends to be sparse and cliquey.  

A quick Google reveals some literature on this area for the reader to pursue if interested (Biem & Caswell, 2008). It also might help you create key performance indicators or metrics to capture how well an organisation is doing at increasing its connectivity.    

### How many connections does each organisation have?  

There are many different ways to assign importance to nodes, we can use the `?centrality_` to help list some options. The centrality of a node measures the importance of node in the network. As the concept of importance is ill-defined and dependent on the network and the questions under consideration, many centrality measures exist.  

```{r}
# the seriation package is required for this
popularity <- inno %>%
  activate(nodes) %>%
  mutate(centrality = centrality_pagerank())

# with the stat calculated we rearrange and select variables
# of interest
popularity %>%
  arrange((centrality), Name) %>%
  as_tibble() %>%
  select(Name, centrality, Type)

```

There's not much difference between the centrality of these nodes. Typically most organisations or projects will have just a few interactions, hence all the tied values. The [Page Rank](https://en.wikipedia.org/wiki/PageRank), is named after Larry Page and is a link analysis algorithm. It assigns a numerical weighting to each element in our innovation network, providing a measure of its relative importance within the set. It's not that useful here.     

```{r}

# the joint least popular
# note we add desc() here
popularity %>%
  arrange(desc(centrality)) %>%
  as_tibble() %>%
  select(Name, centrality, Type) %>%
  slice(1)

# the most popular
# we can use dplyr's useful functions to help, like n()
popularity %>%
  arrange(desc(centrality)) %>%
  as_tibble() %>%
  select(Name, centrality, Type) %>%
  slice(n())

```

Find these nodes on the [innovation network map](https://graphcommons.com/graphs/406e9195-962e-42e6-abf7-8ed2739655c3/selection/bb6ff6c4-3fca-493c-bcea-d9cc6fd2c71f?auto=true) (using the search in the top-left) and count the number of edges. How does this compare to other nodes in the network?  

All these functions are derived from the `netrankr` package so consult the [docs for further detail and philosophy](https://rdrr.io/github/schochastics/netrankr/man/netrankr.html).  

### Who is the most connected (i.e. influential or “important”) organisation?  

There's a whole bunch of useful centrality and grouping strategies described in this excellent [blog post](https://shirinsplayground.netlify.com/2018/03/got_network/) using Game of Thrones characters.  

We implement some of this code from the aforementioned blog here.  

```{r}
# is this correct?!
inno %>%  
  activate(nodes) %>% 
  mutate(neighbors = centrality_degree()) %>%
  arrange(-neighbors)
```

### Are there any important bridges of connectedness?

[Connectedness](http://networksciencebook.com/chapter/2#connectedness) is important.

* Are there clusters of tightly connected organisations?  
* Are there a few key players that connect clusters of organisations?  
* These answers can give us a lot of information about the patterns of how organisations interact across Government.  
* They might help us identify bridges to connect remote areas of Government and share knowledge.  
* This could act as a knowledge repository of sorts for an orgnanisation.  

## Extra questions

You can see how structuring the data as a graph and using tidygraph can allow a user to answer the following questions:

* What emerging tech is department X using?  
* I want to use technology Y, who else is using it?  
* I'm interested in who's worked on projects to do with topic Z. Who else has done somethign similar?  

## Organisational networks, a hierarchy of employees

We now consider employees in an organisation which can be represented by a tree or a hierarchial network graph. Getting your hands on this kind of data can be tricky and also risks falling foul of GDPR. Fortunately we found this package on Github (which we are collaborating on) that makes use of the packages described above to create simulated organisational networks for employees.  

> The goal of `orgsurveyr` is to facilitate the use of Thomas Lin Pedersen's excellent tidygraph and ggraph packages with organisational information used by many Human Resources departments, in particular employee surveys.  

```{r}
# as this in development and may be subject to change
# we install a specific version
devtools::install_github("ukgovdatascience/orgsurveyr@v0.3.0", build_vignettes = TRUE)
library(orgsurveyr)

```

There's an organisation represented as a tidygraph tbl_graph object and generated by the `create_realistic_org` function from `orgsurveyr`.  

```{r}
orgsurveyr::tg_org
```

### Visualising organisation hierarchies

The vignettes of `orgsurveyr` and `ggraph` are very useful and allow us to come-up with interesting use cases.

```{r 2018-08-26-tg_org}
library(ggraph)

graph <- tg_org %>% 
    mutate(mngment_burden = centrality_degree(mode = 'out'))

# plot using ggraph
# perhaps a less charged word than burden? management load?
ggraph(graph, layout = 'kk') + 
    geom_edge_fan(aes(alpha = ..index..), show.legend = FALSE) + 
    geom_node_point(aes(size = mngment_burden)) + 
    theme_graph(foreground = 'steelblue', fg_text_colour = 'white')
```

### Summarising individual level data

Imagine you had a periodic organisation-wide survey (like the People Survey in the [Civil Service](https://www.gov.uk/government/collections/civil-service-people-surveys)) that asked each staff member a few questions, if we structure the data as a graph, it gives us a convenient way to capture all this info and aggregate it at appropriate organisational units. Developing a package to do this could help save analysts' time across your organisation.    

Following the `orgsurveyr` vignette, we can inspect a mapping of where staff members work.   

```{r}
# a mapping of in which business unit staff work
orgsurveyr::tg_org_indiv_minimal_df
```

We could then conduct a "Staff Survey" we record individuals' scores for two questions / tests called `test_var` and `test_var2`. Note how a "name" has been created for an individual, or a unique identifier, by suffixing their `individual_id` onto their `unit_id`.  

```{r}
# we create a "name" 
orgsurveyr::tg_org_indiv_df
```

The individual data can be aggregated at the business unit level. This can be either just those individuals associated with an organisational unit or (more usefully) a cumulative aggregation involving all individuals that are part of that unit and any units below it in the organisation:

```{r}
# the package provides some ready made "People Survey"
summary_df <- calc_summary_df(tg = tg_org, df = orgsurveyr::tg_org_indiv_df, 
                              selected_vars = c('test_var', 'test_var2'),
                              is_cumulative=TRUE)
summary_df
```

If the `is_cumulative flag` is set to `FALSE` then the raw individual to unit mappings are used from the individual data:

```{r}
calc_summary_df(tg = tg_org, df = orgsurveyr::tg_org_indiv_df, 
                              selected_vars = c('test_var', 'test_var2'),
                              is_cumulative=FALSE)
```

How many stafff per business unit?

```{r}
tg_org_indiv_df %>%
  select(unit_id, individual_id) %>%
  dplyr::count(unit_id)
```

If the `is_cumulative flag` is set to `TRUE` then the raw individual to unit mappings are generated from the `generate_cumulative_mapping` function leading to much higher group sizes, this is useful for hierarchical business units where they can be nested inside one another:


```{r}
# tg stands for table graph
generate_cumulative_mapping(tg = tg_org, tg_org_indiv_df) %>%
  dplyr::count(parent_id)
```

As a quick reminder, here we can see the organisational structure grouped by business unit id: 

```{r 2018-08-26-tg_org_starburst}

# A sunburst plot
ggraph(graph, 'partition', circular = TRUE) + 
    geom_node_arc_bar(aes(fill = depth), size = 0.25)
```

Can you pick out the lucky manager at `depth 2` who only manages two people?

You can imagine how the above would help you quickly do the necessary sums and aggregations at the organisational level of interest.  

### Calculating cumulative means for the simulated variable

What about calculating cumulative means for survey results at different business unit levels?  

```{r}
tg_org_indiv_df %>%
  group_by(unit_id) %>%
  dplyr::summarise(test_var = mean(test_var),
                   test_var2 = mean(test_var2))
```

#### Cumulative means in nested business units

Often we don't necessarily want to know the mean for just the people directly associated with an organisational unit, but the mean for all people associated with the current unit _and its children_.  

The vignette for `orgsurveyr` demonstrates how.  

## Publishing your network

### Local options using Docker and neo4j

One can use a [docker file to set-up a Neo4j instance](https://neo4j.com/docs/operations-manual/current/installation/docker/) and then load in your edges and nodes [following these instructions](https://neo4j.com/developer/guide-import-csv/).  

 Here's a shell script that will spin up your instance and create the necessary directories (/import) to put your edge and node csvs. See the guidance above and complete a Docker tutorial before attempting this. We've including this script to save you some time in providing the necessary arguments for your docker instance. The code below will only make sense after completing some tutorials on Docker and Neo4j so skip it for now and revisit later.   

```{r eval=FALSE}
#!/bin/zsh
awhile=2
echo "Be prepared to wait ~10 s for the docker instance to start;
try refreshing browser after brief wait."
# take a while for instance to run
sleep $awhile && open http://localhost:7474/ & 
# think of the foo && bar & as an async call
# that guarantees foo will finish before bar is called
docker run \
    --publish=7474:7474 --publish=7687:7687 \
    --volume=$HOME/neo4j/data:/data \
    --volume=$HOME/neo4j/logs:/logs \
    --volume=$HOME/neo4j/import:/import \
    --env=NEO4J_AUTH=none \
    neo4j
    
    # for docker neo4j setup see
    # https://neo4j.com/developer/docker-23/

exit
```


### Online if non-sensitive

A nice [interactive visualisation](https://graphcommons.com/graphs/406e9195-962e-42e6-abf7-8ed2739655c3__01f6e9de?sel=86e87279-5a15-43ba-ba40-30abd273b109&auto=true&show=info) is provided that uses [Graph Commons](https://graphcommons.com/). You can filter by node and do some basic network analysis using this platform (including clustering).  

There are many [sensible alternatives](https://neo4j.com/developer/guide-data-visualization/), especially if you are looking to scale your network visualisation and analysis. For this you should look to something that uses Neo4j graph database as its backend.  

## Conclusion

This post introduced the fundamentals of network science and used it to create progressively more complicated networks and scratched the surface of some of the questions that can be asked of data structured in this way.  

## References

* Barbasi, A. [Network Science book](http://networksciencebook.com/).  
* Biem, A., & Caswell, N. (2008). A value network model for strategic analysis, 1–7.  
* Borrelli, J. [Simple Food Web Plotting](https://jjborrelli.github.io/post/simple-food-web-plotting/).  
* Pederson, T. L. [Author of ggraph Github](https://github.com/thomasp85/).  
* Saddler, J. [Network analysis with R](https://www.jessesadler.com/post/network-analysis-with-r/).  
* Ognyanova, K. (2016) Network analysis with R and igraph: NetSci X Tutorial. Retrieved from www.kateto.net/networks-r-igraph  
* [SysMIC course](https://sysmic.ac.uk/). Section 1.1.  
* A [bunch of useful references and papers](http://networksciencebook.com/chapter/2#bibliography2).  
* [Tidygraph author blog](https://www.data-imaginist.com/).  
* [Tidygraph presentation](https://www.rstudio.com/resources/videos/tidying-up-your-network-analysis-with-tidygraph-and-ggraph/).  


```{r}
devtools::session_info()
```